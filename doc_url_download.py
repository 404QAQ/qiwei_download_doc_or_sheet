#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
import json
import re
import shutil
import logging
from pathlib import Path
from datetime import datetime
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException

# ---------------- é…ç½®åŒº ----------------
# æ ¹ç›®å½•é…ç½® - ä¼šéå†è¿™ä¸ªç›®å½•ä¸‹çš„æ‰€æœ‰å­ç›®å½•
ROOT_DIRECTORY = os.path.abspath("")  # ä¿®æ”¹ä¸ºä½ çš„æ ¹ç›®å½•

# Cookie é…ç½®
cookie_file = "cookies.json"  # æ”¾åœ¨è„šæœ¬åŒç›®å½•ä¸‹

# æµè§ˆå™¨é…ç½®
USE_REAL_PROFILE = False
CHROME_PROFILE_PATH = ""
PROFILE_NAME = "Default"

headless = False

# è¶…æ—¶è®¾ç½®
PAGE_LOAD_TIMEOUT = 30
WAIT_TIMEOUT = 15
DOWNLOAD_TIMEOUT = 120

# åŸºæœ¬ç­‰å¾…æ—¶é—´
MENU_WAIT = 2
CLICK_WAIT = 1
PAGE_STABLE_WAIT = 3

# ä¸‹è½½è®°å½•æ–‡ä»¶
DOWNLOAD_LOG_FILE = "downloaded_files.txt"

# ---------------------------------------------------------

# é…ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)


def safe_filename(name: str):
    """æ¸…ç†éæ³•æ–‡ä»¶åå­—ç¬¦"""
    name = re.sub(r'[\\/:"*?<>|]+', "_", str(name).strip())
    return name or "unnamed"


def guess_ext_from_url(url: str):
    url = str(url).lower()
    if "sheet" in url:
        return "xlsx"
    if "doc" in url:
        return "docx"
    return "bin"


def format_time(seconds):
    """æ ¼å¼åŒ–æ—¶é—´"""
    if seconds < 60:
        return f"{int(seconds)}ç§’"
    elif seconds < 3600:
        return f"{int(seconds // 60)}åˆ†{int(seconds % 60)}ç§’"
    else:
        return f"{int(seconds // 3600)}å°æ—¶{int((seconds % 3600) // 60)}åˆ†"


def print_progress_bar(current, total, prefix='', length=50):
    """æ‰“å°è¿›åº¦æ¡"""
    percent = current / total
    filled = int(length * percent)
    bar = 'â–ˆ' * filled + 'â–‘' * (length - filled)
    logging.info(f"{prefix} [{bar}] {current}/{total} ({percent*100:.1f}%)")


def log_downloaded_file(filepath, filename):
    """è®°å½•å·²ä¸‹è½½çš„æ–‡ä»¶åˆ°txt"""
    try:
        log_path = os.path.join(ROOT_DIRECTORY, DOWNLOAD_LOG_FILE)
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        with open(log_path, "a", encoding="utf-8") as f:
            f.write(f"[{timestamp}] {filepath} | {filename}\n")
        
        logging.debug(f"ğŸ“ å·²è®°å½•åˆ°ä¸‹è½½æ—¥å¿—: {filename}")
    except Exception as e:
        logging.warning(f"âš ï¸  å†™å…¥ä¸‹è½½æ—¥å¿—å¤±è´¥: {e}")


def setup_browser(download_path, use_profile=False, profile_path="", profile_name="Default"):
    """è®¾ç½®æµè§ˆå™¨"""
    options = uc.ChromeOptions()
    
    # åŸºç¡€è®¾ç½®
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--no-sandbox")
    options.add_argument("--window-size=1920,1080")
    options.add_argument("--lang=zh-CN")
    
    # ä¸‹è½½è®¾ç½® - åŠ¨æ€è®¾ç½®ä¸‹è½½ç›®å½•
    prefs = {
        "download.default_directory": download_path,
        "download.prompt_for_download": False,
        "download.directory_upgrade": True,
        "safebrowsing.enabled": True,
        "profile.default_content_setting_values.notifications": 2,
        "intl.accept_languages": "zh-CN,zh;q=0.9",
    }
    options.add_experimental_option("prefs", prefs)
    
    # ä½¿ç”¨çœŸå®æµè§ˆå™¨ Profile
    if use_profile and profile_path:
        logging.info(f"ä½¿ç”¨çœŸå®æµè§ˆå™¨ Profile: {profile_path}/{profile_name}")
        options.add_argument(f"--user-data-dir={profile_path}")
        options.add_argument(f"--profile-directory={profile_name}")
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-software-rasterizer")
    
    try:
        logging.info("ğŸš€ æ­£åœ¨å¯åŠ¨ Chrome æµè§ˆå™¨...")
        driver = uc.Chrome(
            options=options,
            version_main=None,
            headless=False,
            use_subprocess=False,
            log_level=3,
        )
        
        driver.set_page_load_timeout(PAGE_LOAD_TIMEOUT)
        driver.set_script_timeout(30)
        
        logging.info("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
        return driver
        
    except Exception as e:
        logging.error(f"âŒ å¯åŠ¨æµè§ˆå™¨å¤±è´¥: {e}")
        raise


def load_cookies_from_file(path: str) -> list:
    """ä» JSON æ–‡ä»¶è¯»å– cookie"""
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
            
            if isinstance(data, list):
                return data
            
            if isinstance(data, dict):
                cookies = []
                for name, value in data.items():
                    cookies.append({
                        "name": name,
                        "value": value,
                        "domain": ".weixin.qq.com",
                        "path": "/",
                        "secure": True,
                        "httpOnly": False
                    })
                return cookies
    except Exception as e:
        logging.warning(f"âš ï¸  è¯»å– cookie_file å¤±è´¥: {e}")
    return []


def add_cookies(driver, cookies_list, domain="doc.weixin.qq.com"):
    """æ³¨å…¥ cookie"""
    if not cookies_list:
        return
    
    driver.get(f"https://{domain}")
    time.sleep(2)
    
    success_count = 0
    for cookie in cookies_list:
        try:
            if "name" not in cookie or "value" not in cookie:
                continue
            
            cookie_dict = {
                "name": cookie["name"],
                "value": cookie["value"],
                "domain": cookie.get("domain", domain),
                "path": cookie.get("path", "/"),
                "secure": cookie.get("secure", True),
            }
            
            if "httpOnly" in cookie:
                cookie_dict["httpOnly"] = cookie["httpOnly"]
            if "sameSite" in cookie:
                cookie_dict["sameSite"] = cookie["sameSite"]
            if "expiry" in cookie:
                cookie_dict["expiry"] = cookie["expiry"]
            
            driver.add_cookie(cookie_dict)
            success_count += 1
        except Exception as e:
            logging.debug(f"æ³¨å…¥ cookie {cookie.get('name')} å¤±è´¥: {e}")
    
    logging.info(f"âœ… æˆåŠŸæ³¨å…¥ {success_count}/{len(cookies_list)} ä¸ª cookie")
    time.sleep(2)


def wait_for_new_download(before_files, download_folder, timeout=DOWNLOAD_TIMEOUT):
    """ç­‰å¾…ä¸‹è½½å®Œæˆ - æ”¹è¿›ç‰ˆæœ¬"""
    start = time.time()
    logging.info(f"â³ å¼€å§‹ç­‰å¾…ä¸‹è½½ (è¶…æ—¶: {timeout}ç§’)")
    logging.info(f"   ä¸‹è½½ç›®å½•: {download_folder}")
    logging.info(f"   ä¸‹è½½å‰æ–‡ä»¶æ•°: {len(before_files)}")
    
    # å®šæœŸæ£€æŸ¥
    check_interval = 5  # æ¯5ç§’æŠ¥å‘Šä¸€æ¬¡è¿›åº¦
    last_check_time = start
    
    while time.time() - start < timeout:
        current_time = time.time()
        
        # è·å–å½“å‰æ–‡ä»¶åˆ—è¡¨
        try:
            now_files = {p.name for p in Path(download_folder).iterdir() if p.is_file()}
        except Exception as e:
            logging.warning(f"âš ï¸  è¯»å–ç›®å½•å¤±è´¥: {e}")
            time.sleep(1)
            continue
        
        new_files = now_files - before_files
        
        # å®šæœŸè¾“å‡ºè¿›åº¦ä¿¡æ¯
        if current_time - last_check_time >= check_interval:
            elapsed = int(current_time - start)
            logging.info(f"   [{elapsed}s] å½“å‰æ–‡ä»¶æ•°: {len(now_files)}, æ–°å¢: {len(new_files)}")
            if new_files:
                logging.info(f"   æ–°æ–‡ä»¶åˆ—è¡¨: {list(new_files)}")
            last_check_time = current_time
        
        if new_files:
            # æ’é™¤ä¸´æ—¶æ–‡ä»¶
            valid_files = [f for f in new_files 
                          if not f.endswith('.crdownload') 
                          and not f.endswith('.tmp')
                          and not f.startswith('.')
                          and not f.startswith('~')]
            
            if not valid_files:
                logging.debug("   åªæœ‰ä¸´æ—¶æ–‡ä»¶ï¼Œç»§ç»­ç­‰å¾…...")
                time.sleep(1)
                continue
            
            # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶
            candidate = Path(download_folder) / sorted(valid_files)[0]
            logging.info(f"   ğŸ” æ£€æµ‹åˆ°æ–°æ–‡ä»¶: {candidate.name}")
            
            # ç­‰å¾…æ–‡ä»¶ç¨³å®š
            stable_checks = 0
            stable_needed = 3  # éœ€è¦3æ¬¡æ£€æŸ¥éƒ½ç¨³å®š
            last_size = -1
            
            for check_num in range(10):  # æœ€å¤šæ£€æŸ¥10æ¬¡
                if not candidate.exists():
                    logging.warning(f"   âš ï¸  æ–‡ä»¶æ¶ˆå¤±: {candidate.name}")
                    break
                
                try:
                    current_size = candidate.stat().st_size
                    
                    if current_size == last_size and current_size > 0:
                        stable_checks += 1
                        logging.info(f"   âœ“ æ–‡ä»¶ç¨³å®šæ£€æŸ¥: {stable_checks}/{stable_needed} ({current_size:,} bytes)")
                        
                        if stable_checks >= stable_needed:
                            file_size_mb = current_size / (1024 * 1024)
                            logging.info(f"âœ… æ–‡ä»¶ä¸‹è½½å®Œæˆ: {candidate.name} ({file_size_mb:.2f} MB)")
                            return str(candidate)
                    else:
                        if last_size != -1:
                            logging.info(f"   â¬ æ–‡ä»¶å¤§å°å˜åŒ–: {last_size:,} â†’ {current_size:,} bytes")
                        stable_checks = 0
                        last_size = current_size
                    
                    time.sleep(1)
                    
                except Exception as e:
                    logging.warning(f"   âš ï¸  æ£€æŸ¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                    time.sleep(1)
        
        time.sleep(1)
    
    # è¶…æ—¶ååšæœ€åæ£€æŸ¥
    logging.warning("âš ï¸  ä¸‹è½½ç­‰å¾…è¶…æ—¶ï¼Œåšæœ€åæ£€æŸ¥...")
    try:
        final_files = {p.name for p in Path(download_folder).iterdir() if p.is_file()}
        final_new = final_files - before_files
        if final_new:
            # è¿”å›æœ€æ–°çš„éä¸´æ—¶æ–‡ä»¶
            valid = [Path(download_folder) / f for f in final_new 
                    if not f.endswith(('.crdownload', '.tmp')) and not f.startswith('.')]
            if valid:
                latest = max(valid, key=lambda f: f.stat().st_mtime)
                logging.info(f"âœ… æ‰¾åˆ°æ–‡ä»¶: {latest.name}")
                return str(latest)
    except Exception as e:
        logging.error(f"âŒ æœ€åæ£€æŸ¥å¤±è´¥: {e}")
    
    return None


def update_download_directory(driver, new_download_path):
    """åŠ¨æ€æ›´æ–°æµè§ˆå™¨ä¸‹è½½ç›®å½•"""
    try:
        driver.execute_cdp_cmd("Page.setDownloadBehavior", {
            "behavior": "allow",
            "downloadPath": new_download_path
        })
        logging.info(f"ğŸ“ ä¸‹è½½ç›®å½•å·²æ›´æ–°ä¸º: {new_download_path}")
    except Exception as e:
        logging.warning(f"âš ï¸  æ›´æ–°ä¸‹è½½ç›®å½•å¤±è´¥: {e}")


def save_debug(driver, prefix, current_dir=None):
    """ä¿å­˜è°ƒè¯•ä¿¡æ¯"""
    debug_dir = os.path.join(current_dir if current_dir else "debug", "debug")
    os.makedirs(debug_dir, exist_ok=True)
    
    ts = int(time.time())
    html_path = os.path.join(debug_dir, f"{prefix}_{ts}.html")
    png_path = os.path.join(debug_dir, f"{prefix}_{ts}.png")
    
    try:
        with open(html_path, "w", encoding="utf-8") as f:
            f.write(driver.page_source)
        driver.save_screenshot(png_path)
        logging.info(f"ğŸ’¾ å·²ä¿å­˜è°ƒè¯•æ–‡ä»¶ï¼š{html_path}, {png_path}")
    except Exception as e:
        logging.warning(f"âš ï¸  ä¿å­˜è°ƒè¯•æ–‡ä»¶å¤±è´¥: {e}")


def check_file_exists(directory, filename, url):
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨"""
    # è·å–æœŸæœ›çš„æ–‡ä»¶æ‰©å±•å
    ext = guess_ext_from_url(url)
    full_filename = f"{safe_filename(filename)}.{ext}"
    file_path = Path(directory) / full_filename
    
    if file_path.exists():
        logging.info(f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {full_filename}")
        return True
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¸¦ç¼–å·çš„ç‰ˆæœ¬
    i = 1
    while True:
        alt_filename = f"{safe_filename(filename)}({i}).{ext}"
        alt_path = Path(directory) / alt_filename
        if alt_path.exists():
            logging.info(f"â­ï¸  æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {alt_filename}")
            return True
        if not alt_path.exists():
            break
        i += 1
    
    return False


def click_export_and_download(driver, name, url, idx, total, download_dir, before_files):
    """ç‚¹å‡»å¯¼å‡ºå¹¶ä¸‹è½½ - æ”¹è¿›ç‰ˆæœ¬"""
    
    url_l = url.lower()
    is_sheet = "sheet" in url_l
    is_doc = "doc" in url_l and "sheet" not in url_l
    
    doc_type = "è¡¨æ ¼" if is_sheet else "æ–‡æ¡£" if is_doc else "æ–‡ä»¶"
    
    try:
        # 1. ç‚¹å‡»èœå•
        logging.info(f"ğŸ” [{idx}/{total}] æŸ¥æ‰¾èœå•æŒ‰é’®...")
        menu = WebDriverWait(driver, WAIT_TIMEOUT).until(
            EC.element_to_be_clickable((By.ID, "main-menu-file"))
        )
        menu.click()
        logging.info(f"âœ… èœå•æŒ‰é’®å·²ç‚¹å‡»")
        time.sleep(MENU_WAIT)
        
        # 2. ç‚¹å‡»å¯¼å‡º
        logging.info(f"ğŸ” æŸ¥æ‰¾å¯¼å‡ºæŒ‰é’®...")
        if is_sheet:
            export_xpaths = [
                "//li[contains(@class,'mainmenu-submenu-exportAs') and contains(normalize-space(.),'å¯¼å‡º')]",
                "//li[contains(@class,'mainmenu-submenu') and contains(normalize-space(.),'å¯¼å‡º')]",
            ]
        else:
            export_xpaths = [
                "//li[contains(@class,'mainmenu-submenu-export-as') and contains(normalize-space(.),'å¯¼å‡º')]",
                "//li[contains(@class,'mainmenu-submenu') and contains(normalize-space(.),'å¯¼å‡º')]",
            ]
        
        export_li = None
        for xpath_idx, xpath in enumerate(export_xpaths, 1):
            try:
                logging.debug(f"   å°è¯• XPath {xpath_idx}/{len(export_xpaths)}")
                export_li = WebDriverWait(driver, 5).until(
                    EC.element_to_be_clickable((By.XPATH, xpath))
                )
                logging.info(f"âœ… æ‰¾åˆ°å¯¼å‡ºæŒ‰é’®ï¼ˆXPath {xpath_idx}ï¼‰")
                break
            except TimeoutException:
                continue
        
        if not export_li:
            return None, "æœªæ‰¾åˆ°å¯¼å‡ºæŒ‰é’®"
        
        export_li.click()
        logging.info(f"âœ… å¯¼å‡ºæŒ‰é’®å·²ç‚¹å‡»")
        time.sleep(CLICK_WAIT)
        
        # 3. é€‰æ‹©å¯¼å‡ºç±»å‹
        logging.info(f"ğŸ” æŸ¥æ‰¾å¯¼å‡ºç±»å‹é€‰é¡¹ï¼ˆ{doc_type}ï¼‰...")
        if is_sheet:
            export_type_xpaths = [
                "//li[contains(@class,'mainmenu-item-export-local') and contains(normalize-space(.),'æœ¬åœ°')]",
                "//li[contains(@class,'export-local') and contains(normalize-space(.),'æœ¬åœ°')]",
            ]
        elif is_doc:
            export_type_xpaths = [
                "//li[contains(@class,'mainmenu-item-export-as-docx') and contains(normalize-space(.),'æœ¬åœ°')]",
                "//li[contains(@class,'export-as-docx') and contains(normalize-space(.),'æœ¬åœ°')]",
            ]
        else:
            export_type_xpaths = [
                "//*[contains(normalize-space(.),'æœ¬åœ°') and (self::li or self::button)]",
            ]
        
        target = None
        for xpath_idx, xpath in enumerate(export_type_xpaths, 1):
            try:
                logging.debug(f"   å°è¯•å¯¼å‡ºç±»å‹ XPath {xpath_idx}/{len(export_type_xpaths)}")
                target = WebDriverWait(driver, 5).until(
                    EC.element_to_be_clickable((By.XPATH, xpath))
                )
                logging.info(f"âœ… æ‰¾åˆ°å¯¼å‡ºç±»å‹é€‰é¡¹ï¼ˆXPath {xpath_idx}ï¼‰")
                break
            except TimeoutException:
                continue
        
        if not target:
            return None, "æœªæ‰¾åˆ°å¯¼å‡ºç±»å‹é€‰é¡¹"
        
        # ç‚¹å‡»å‰è®°å½•æ–‡ä»¶åˆ—è¡¨
        before_click_files = {p.name for p in Path(download_dir).iterdir() if p.is_file()}
        logging.info(f"ğŸ“Š ç‚¹å‡»å‰æ–‡ä»¶æ•°: {len(before_click_files)}")
        
        target.click()
        logging.info(f"âœ… å¯¼å‡ºç±»å‹å·²é€‰æ‹©ï¼Œå¼€å§‹ä¸‹è½½...")
        
        # ç‚¹å‡»åç«‹å³æ£€æŸ¥æ˜¯å¦æœ‰å¼¹çª—
        time.sleep(2)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¡®è®¤æŒ‰é’®æˆ–å…¶ä»–å¼¹çª—
        try:
            confirm_buttons = driver.find_elements(By.XPATH, 
                "//button[contains(normalize-space(.),'ç¡®å®š') or "
                "contains(normalize-space(.),'ç¡®è®¤') or "
                "contains(normalize-space(.),'ä¸‹è½½')]"
            )
            if confirm_buttons:
                logging.info(f"ğŸ” å‘ç° {len(confirm_buttons)} ä¸ªç¡®è®¤æŒ‰é’®")
                for btn in confirm_buttons:
                    if btn.is_displayed():
                        btn.click()
                        logging.info(f"âœ… ç‚¹å‡»äº†ç¡®è®¤æŒ‰é’®")
                        time.sleep(1)
                        break
        except Exception as e:
            logging.debug(f"æ£€æŸ¥ç¡®è®¤æŒ‰é’®æ—¶å‡ºé”™: {e}")
        
        # å†æ¬¡è®°å½•æ–‡ä»¶åˆ—è¡¨ç”¨äºæ¯”è¾ƒ
        after_click_files = {p.name for p in Path(download_dir).iterdir() if p.is_file()}
        new_immediate = after_click_files - before_click_files
        if new_immediate:
            logging.info(f"âš¡ ç‚¹å‡»åç«‹å³å‡ºç°æ–°æ–‡ä»¶: {list(new_immediate)}")
        
        # ç­‰å¾…ä¸‹è½½
        downloaded = wait_for_new_download(before_files, download_dir, timeout=DOWNLOAD_TIMEOUT)
        
        return downloaded, "æˆåŠŸ" if downloaded else "ä¸‹è½½è¶…æ—¶"
        
    except TimeoutException as e:
        logging.warning(f"âš ï¸  ç­‰å¾…é¡µé¢å…ƒç´ è¶…æ—¶: {e}")
        return None, "å…ƒç´ è¶…æ—¶"
    except Exception as e:
        logging.warning(f"âš ï¸  è‡ªåŠ¨ç‚¹å‡»å¯¼å‡ºå¤±è´¥: {e}")
        return None, f"ç‚¹å‡»å¤±è´¥: {str(e)}"


def process_directory(directory_path, driver, dir_idx, total_dirs):
    """å¤„ç†å•ä¸ªç›®å½• - ä¿®å¤è¿”å›å€¼é—®é¢˜"""
    json_file = os.path.join(directory_path, "data.json")
    
    if not os.path.exists(json_file):
        logging.warning(f"âš ï¸  ç›®å½• {directory_path} ä¸­æ²¡æœ‰ data.json")
        return 0, 0, 0, "æ— data.jsonæ–‡ä»¶"
    
    dir_name = os.path.basename(directory_path)
    logging.info(f"\n{'='*80}")
    logging.info(f"ğŸ“‚ [{dir_idx}/{total_dirs}] å¤„ç†ç›®å½•: {dir_name}")
    logging.info(f"   è·¯å¾„: {directory_path}")
    logging.info(f"{'='*80}")
    
    # è¯»å– JSON
    try:
        with open(json_file, "r", encoding="utf-8") as f:
            data = json.load(f)
    except Exception as e:
        logging.error(f"âŒ æ— æ³•è¯»å– JSON æ–‡ä»¶ {json_file}: {e}")
        return 0, 0, 0, "JSONè¯»å–å¤±è´¥"
    
    infos = data.get("body", {}).get("file_list", [])
    if not infos:
        logging.warning("âš ï¸  JSON ä¸­æœªæ‰¾åˆ° file_listï¼Œè·³è¿‡æ­¤ç›®å½•")
        return 0, 0, 0, "æ— file_listæ•°æ®"
    
    logging.info(f"ğŸ“Š æœ¬ç›®å½•å…±æœ‰ {len(infos)} ä¸ªæ–‡æ¡£å¾…å¤„ç†")
    
    # æ›´æ–°ä¸‹è½½ç›®å½•ä¸ºå½“å‰ç›®å½•
    download_dir = directory_path
    update_download_directory(driver, download_dir)
    
    # ä¸»å¾ªç¯
    success_count = 0
    failed_count = 0
    skipped_count = 0
    failed_details = []
    
    start_time = time.time()
    
    for idx, info in enumerate(infos, start=1):
        name_raw = info.get("name", f"doc_{idx}")
        name = safe_filename(name_raw)
        url = info.get("doc_url")
        
        # æ˜¾ç¤ºè¿›åº¦
        logging.info(f"\n{'â”€'*80}")
        print_progress_bar(idx - 1, len(infos), prefix=f'ğŸ“ˆ ç›®å½•è¿›åº¦')
        logging.info(f"ğŸ“„ [{idx}/{len(infos)}] æ­£åœ¨å¤„ç†: {name}")
        logging.info(f"   URL: {url[:80]}..." if len(url) > 80 else f"   URL: {url}")
        
        if not url:
            logging.warning(f"âš ï¸  æœªæä¾› doc_urlï¼Œè·³è¿‡")
            failed_count += 1
            failed_details.append((name, "æ— URL"))
            continue
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        if check_file_exists(download_dir, name, url):
            skipped_count += 1
            continue
        
        # æ‰“å¼€é¡µé¢
        try:
            logging.info(f"ğŸŒ æ‰“å¼€é¡µé¢...")
            driver.get(url)
            time.sleep(PAGE_STABLE_WAIT)
            logging.info(f"âœ… é¡µé¢åŠ è½½å®Œæˆ")
            
        except Exception as e:
            logging.warning(f"âŒ æ‰“å¼€é¡µé¢å¼‚å¸¸: {e}")
            save_debug(driver, f"{idx}_{name}_open_err", download_dir)
            failed_count += 1
            failed_details.append((name, "æ‰“å¼€å¤±è´¥"))
            continue
        
        # åœ¨ç‚¹å‡»ä¸‹è½½å‰è®°å½•æ–‡ä»¶åˆ—è¡¨
        before_files = {p.name for p in Path(download_dir).iterdir() if p.is_file()}
        
        # ç‚¹å‡»å¯¼å‡ºå¹¶ä¸‹è½½
        downloaded, status = click_export_and_download(
            driver, name, url, idx, len(infos), download_dir, before_files
        )
        
        if not downloaded:
            logging.warning(f"âŒ ä¸‹è½½å¤±è´¥: {status}")
            save_debug(driver, f"{idx}_{name}_{status}", download_dir)
            failed_count += 1
            failed_details.append((name, status))
            continue
        
        # é‡å‘½åæ–‡ä»¶
        src = Path(downloaded)
        ext = src.suffix if src.suffix else f".{guess_ext_from_url(url)}"
        
        # ç›®æ ‡æ–‡ä»¶åï¼ˆä¸å¸¦åç¼€ï¼‰
        dest = Path(download_dir) / f"{name}{ext}"
        
        # å¦‚æœä¸‹è½½çš„æ–‡ä»¶å·²ç»æ˜¯æ­£ç¡®çš„åå­—ï¼Œå°±ä¸éœ€è¦é‡å‘½å
        if src == dest:
            file_size_mb = dest.stat().st_size / (1024 * 1024)
            logging.info(f"âœ… ä¸‹è½½å®Œæˆ: {dest.name} ({file_size_mb:.2f} MB)")
            
            # è®°å½•åˆ°ä¸‹è½½æ—¥å¿—
            rel_path = os.path.relpath(str(dest), ROOT_DIRECTORY)
            log_downloaded_file(rel_path, dest.name)
            
            success_count += 1
        else:
            # éœ€è¦é‡å‘½åï¼Œæ£€æŸ¥ç›®æ ‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if dest.exists():
                i = 1
                while True:
                    alt = Path(download_dir) / f"{name}({i}){ext}"
                    if not alt.exists():
                        dest = alt
                        break
                    i += 1
            
            try:
                shutil.move(str(src), str(dest))
                file_size_mb = dest.stat().st_size / (1024 * 1024)
                logging.info(f"âœ… ä¸‹è½½å®Œæˆ: {dest.name} ({file_size_mb:.2f} MB)")
                
                # è®°å½•åˆ°ä¸‹è½½æ—¥å¿—
                rel_path = os.path.relpath(str(dest), ROOT_DIRECTORY)
                log_downloaded_file(rel_path, dest.name)
                
                success_count += 1
            except Exception as e:
                logging.warning(f"âŒ é‡å‘½åå¤±è´¥: {e}")
                failed_count += 1
                failed_details.append((name, "é‡å‘½åå¤±è´¥"))
                continue
        
        # ç®€å•çš„é—´éš”
        if idx < len(infos):
            time.sleep(2)
    
    # è®¡ç®—è€—æ—¶
    elapsed_time = time.time() - start_time
    
    # è¾“å‡ºå½“å‰ç›®å½•çš„å¤„ç†ç»“æœ
    logging.info(f"\n{'='*80}")
    logging.info(f"ğŸ“Š ç›®å½• [{dir_name}] å¤„ç†å®Œæˆ")
    logging.info(f"{'='*80}")
    logging.info(f"âœ… æˆåŠŸ: {success_count}")
    logging.info(f"â­ï¸  è·³è¿‡: {skipped_count}")
    logging.info(f"âŒ å¤±è´¥: {failed_count}")
    logging.info(f"â±ï¸  è€—æ—¶: {format_time(elapsed_time)}")
    
    if failed_details:
        logging.info(f"\nå¤±è´¥è¯¦æƒ…:")
        for name, reason in failed_details:
            logging.info(f"  âŒ {name}: {reason}")
    
    return success_count, failed_count, skipped_count, "å®Œæˆ"


def main():
    start_time = time.time()
    
    logging.info("=" * 80)
    logging.info("ğŸš€ ä¼ä¸šå¾®ä¿¡æ–‡æ¡£æ‰¹é‡ä¸‹è½½å·¥å…·ï¼ˆç›®å½•éå†ç‰ˆï¼‰")
    logging.info("=" * 80)
    logging.info(f"ğŸ“ æ ¹ç›®å½•: {ROOT_DIRECTORY}")
    logging.info(f"â° å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info("=" * 80)
    
    if not os.path.exists(ROOT_DIRECTORY):
        logging.error(f"âŒ æ ¹ç›®å½•ä¸å­˜åœ¨: {ROOT_DIRECTORY}")
        return
    
    # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«data.jsonçš„ç›®å½•
    directories_with_data = []
    logging.info("ğŸ” æ­£åœ¨æ‰«æç›®å½•...")
    for root, dirs, files in os.walk(ROOT_DIRECTORY):
        if "data.json" in files:
            directories_with_data.append(root)
            rel_path = os.path.relpath(root, ROOT_DIRECTORY)
            logging.info(f"   âœ“ æ‰¾åˆ°: {rel_path}")
    
    if not directories_with_data:
        logging.warning("âš ï¸  æœªæ‰¾åˆ°åŒ…å«data.jsonçš„ç›®å½•")
        return
    
    # æŒ‰è·¯å¾„æ·±åº¦æ’åºï¼Œç¡®ä¿å…ˆå¤„ç†çˆ¶ç›®å½•
    directories_with_data.sort(key=lambda x: x.count(os.sep))
    
    logging.info(f"\nâœ… æ‰¾åˆ° {len(directories_with_data)} ä¸ªåŒ…å«data.jsonçš„ç›®å½•:")
    for i, directory in enumerate(directories_with_data, 1):
        rel_path = os.path.relpath(directory, ROOT_DIRECTORY)
        logging.info(f"   {i}. {rel_path}")
    
    # å¯åŠ¨æµè§ˆå™¨
    logging.info(f"\n{'='*80}")
    logging.info("ğŸŒ æ­£åœ¨å¯åŠ¨æµè§ˆå™¨...")
    logging.info("=" * 80)
    driver = setup_browser(
        ROOT_DIRECTORY,  # åˆå§‹ä¸‹è½½ç›®å½•è®¾ä¸ºæ ¹ç›®å½•
        use_profile=USE_REAL_PROFILE,
        profile_path=CHROME_PROFILE_PATH,
        profile_name=PROFILE_NAME
    )
    
    # å¦‚æœä¸ä½¿ç”¨ profileï¼Œåˆ™éœ€è¦åŠ è½½ cookie
    if not USE_REAL_PROFILE:
        cookies_list = load_cookies_from_file(cookie_file) if os.path.exists(cookie_file) else []
        if cookies_list:
            logging.info(f"ğŸ” æ­£åœ¨æ³¨å…¥ {len(cookies_list)} ä¸ª cookie...")
            add_cookies(driver, cookies_list)
        else:
            logging.warning("âš ï¸  æœªæä¾› cookie ä¸”æœªä½¿ç”¨ profileï¼Œå¯èƒ½éœ€è¦æ‰‹åŠ¨ç™»å½•")
            logging.info("ğŸ‘‰ è¯·åœ¨æ‰“å¼€çš„æµè§ˆå™¨ä¸­ç™»å½•ï¼Œç„¶åæŒ‰å›è½¦ç»§ç»­...")
            input()
    else:
        logging.info("âœ… ä½¿ç”¨çœŸå®æµè§ˆå™¨ Profileï¼Œå·²è‡ªåŠ¨ç™»å½•")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_success = 0
    total_failed = 0
    total_skipped = 0
    directory_results = []
    
    # å¤„ç†æ¯ä¸ªç›®å½•
    for idx, directory in enumerate(directories_with_data, 1):
        try:
            # è°ƒç”¨ process_directoryï¼Œç¡®ä¿æ€»æ˜¯è¿”å›4ä¸ªå€¼
            result = process_directory(directory, driver, idx, len(directories_with_data))
            
            # æ£€æŸ¥è¿”å›å€¼
            if result is None or len(result) != 4:
                logging.error(f"âŒ process_directory è¿”å›å€¼å¼‚å¸¸: {result}")
                success, failed, skipped, status = 0, 0, 0, "è¿”å›å€¼å¼‚å¸¸"
            else:
                success, failed, skipped, status = result
            
            total_success += success
            total_failed += failed
            total_skipped += skipped
            
            directory_results.append({
                'directory': os.path.relpath(directory, ROOT_DIRECTORY),
                'success': success,
                'failed': failed,
                'skipped': skipped,
                'status': status
            })
            
            # æ˜¾ç¤ºæ€»ä½“è¿›åº¦
            logging.info(f"\n{'='*80}")
            print_progress_bar(idx, len(directories_with_data), prefix='ğŸ¯ æ€»ä½“è¿›åº¦')
            logging.info(f"ğŸ“Š ç´¯è®¡ç»Ÿè®¡: æˆåŠŸ {total_success} | è·³è¿‡ {total_skipped} | å¤±è´¥ {total_failed}")
            logging.info(f"{'='*80}")
            
            # ç›®å½•é—´ä¼‘æ¯
            if idx < len(directories_with_data):
                logging.info(f"\nâ¸ï¸  ä¼‘æ¯ 3 ç§’åå¤„ç†ä¸‹ä¸€ä¸ªç›®å½•...")
                time.sleep(3)
                
        except Exception as e:
            logging.error(f"âŒ å¤„ç†ç›®å½• {directory} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
            import traceback
            logging.error(traceback.format_exc())
            
            directory_results.append({
                'directory': os.path.relpath(directory, ROOT_DIRECTORY),
                'success': 0,
                'failed': 0,
                'skipped': 0,
                'status': f"å¼‚å¸¸: {str(e)}"
            })
    
    driver.quit()
    logging.info("\nğŸ”’ æµè§ˆå™¨å·²å…³é—­")
    
    # è®¡ç®—æ€»è€—æ—¶
    total_time = time.time() - start_time
    
    # æœ€ç»ˆç»Ÿè®¡
    logging.info(f"\n{'='*80}")
    logging.info("ğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼")
    logging.info("=" * 80)
    logging.info(f"â° ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info(f"â±ï¸  æ€»è€—æ—¶: {format_time(total_time)}")
    logging.info(f"\nğŸ“Š æœ€ç»ˆç»Ÿè®¡:")
    logging.info(f"   âœ… æ€»æˆåŠŸ: {total_success}")
    logging.info(f"   â­ï¸  æ€»è·³è¿‡: {total_skipped}")
    logging.info(f"   âŒ æ€»å¤±è´¥: {total_failed}")
    logging.info(f"   ğŸ“ å¤„ç†ç›®å½•: {len(directories_with_data)}")
    
    if total_success + total_failed > 0:
        success_rate = (total_success / (total_success + total_failed)) * 100
        logging.info(f"   ğŸ“ˆ æˆåŠŸç‡: {success_rate:.1f}%")
    
    # è¯¦ç»†ç»“æœè¡¨
    logging.info(f"\n{'='*80}")
    logging.info("ğŸ“‹ å„ç›®å½•å¤„ç†ç»“æœ:")
    logging.info("=" * 80)
    logging.info(f"{'ç›®å½•':<40} {'æˆåŠŸ':>8} {'è·³è¿‡':>8} {'å¤±è´¥':>8} {'çŠ¶æ€':<15}")
    logging.info("-" * 80)
    
    for result in directory_results:
        dir_name = result['directory']
        if len(dir_name) > 38:
            dir_name = "..." + dir_name[-35:]
        
        success = result['success']
        skipped = result['skipped']
        failed = result['failed']
        status = result['status']
        
        # æ ¹æ®çŠ¶æ€é€‰æ‹©å›¾æ ‡
        if status == "å®Œæˆ" and failed == 0:
            icon = "âœ…"
        elif status == "å®Œæˆ" and failed > 0:
            icon = "âš ï¸"
        else:
            icon = "âŒ"
        
        logging.info(f"{dir_name:<40} {success:>8} {skipped:>8} {failed:>8} {icon} {status:<15}")
    
    logging.info("=" * 80)
    
    # ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶
    try:
        result_file = os.path.join(ROOT_DIRECTORY, f"download_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
        with open(result_file, "w", encoding="utf-8") as f:
            json.dump({
                "start_time": datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S'),
                "end_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "total_time_seconds": int(total_time),
                "total_success": total_success,
                "total_failed": total_failed,
                "total_skipped": total_skipped,
                "total_directories": len(directories_with_data),
                "directory_results": directory_results
            }, f, ensure_ascii=False, indent=2)
        logging.info(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
    except Exception as e:
        logging.warning(f"âš ï¸  ä¿å­˜ç»“æœæ–‡ä»¶å¤±è´¥: {e}")
    
    # æ˜¾ç¤ºä¸‹è½½æ—¥å¿—æ–‡ä»¶ä½ç½®
    log_file_path = os.path.join(ROOT_DIRECTORY, DOWNLOAD_LOG_FILE)
    if os.path.exists(log_file_path):
        logging.info(f"ğŸ“ ä¸‹è½½æ–‡ä»¶æ—¥å¿—: {log_file_path}")
    
    logging.info("\nâœ¨ ç¨‹åºæ‰§è¡Œå®Œæ¯•ï¼")


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        logging.info("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        logging.error(f"\n\nâŒ ç¨‹åºå¼‚å¸¸é€€å‡º: {e}")
        import traceback
        logging.error(traceback.format_exc())
    finally:
        logging.info("\nğŸ‘‹ å†è§ï¼")
